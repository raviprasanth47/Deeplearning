{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "C7WiKjxDtWAN",
    "outputId": "6b1f41d7-18a6-41a6-ea34-553966ee883f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('gdrive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "colab_type": "code",
    "id": "_r2cejfqyVit",
    "outputId": "28872c17-27c8-44c2-faff-750adc5bcb5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.13.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n",
      "\u001b[K     |████████████████████████████████| 92.5MB 340kB/s \n",
      "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.2.2)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.8.0)\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow==1.13.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "\u001b[K     |████████████████████████████████| 368kB 39.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.12.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.8.0)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow==1.13.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 27.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.16.5)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.33.6)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (3.7.1)\n",
      "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (0.16.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.8.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (41.2.0)\n",
      "Installing collected packages: mock, tensorflow-estimator, tensorboard, tensorflow\n",
      "  Found existing installation: tensorflow-estimator 1.15.1\n",
      "    Uninstalling tensorflow-estimator-1.15.1:\n",
      "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
      "  Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "  Found existing installation: tensorflow 1.15.0rc3\n",
      "    Uninstalling tensorflow-1.15.0rc3:\n",
      "      Successfully uninstalled tensorflow-1.15.0rc3\n",
      "Successfully installed mock-3.0.5 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "tensorboard",
         "tensorflow",
         "tensorflow_estimator"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install tensorflow==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dvPLDVrTbqpv"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "10VYOqpZpjtn",
    "outputId": "9b0163a3-9565-4165-d6b2-d4ff125fc63a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01OkY_MJ0XTv"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YXP75OkAbzyj"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Input,Flatten,Dropout\n",
    "from keras import optimizers\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lAPuR305o2Pt"
   },
   "outputs": [],
   "source": [
    "project_data = pd.read_csv('gdrive/My Drive/preprocessed_data_donors_choose.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "bsObQ_BwpVXF",
    "outputId": "872fada1-6ce4-48ef-8d2c-4e589999aac6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>725.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>213.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>having class 24 students comes diverse learner...</td>\n",
       "      <td>329.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state  ...   price\n",
       "0           ca  ...  725.05\n",
       "1           ut  ...  213.03\n",
       "2           ca  ...  329.00\n",
       "\n",
       "[3 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "asHUwjQvbo36",
    "outputId": "edce6c1c-16c5-4079-94a6-c7b8df70d29b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    92706\n",
       "0    16542\n",
       "Name: project_is_approved, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['project_is_approved'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-899WN1e4nH"
   },
   "outputs": [],
   "source": [
    "# scaling the values with mean=0 and std_dev=1 for numerical features\n",
    "scaler=StandardScaler()\n",
    "project_data[['teacher_number_of_previously_posted_projects','price']]=scaler.fit_transform(project_data[['teacher_number_of_previously_posted_projects','price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "8fDtXuLbyteu",
    "outputId": "c097be50-1a5c-4ae4-b9fb-ab1c98c70ca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n"
     ]
    }
   ],
   "source": [
    "#printing the number of word in the 1st essay\n",
    "print((len(project_data['essay'].values[0].split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWECHJ0zLgt3"
   },
   "outputs": [],
   "source": [
    "Y=project_data['project_is_approved'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FuFG1KV7KNBk"
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "train_text,test_text,train_state,test_state,train_grade,test_grade,train_category,test_category,train_sub,test_sub,train_teacher,test_teacher,train_posted,test_posted,train_price,test_price,y_train,y_test=train_test_split(project_data['essay'],project_data['school_state'],project_data['project_grade_category'],project_data['clean_categories'],project_data['clean_subcategories'],project_data['teacher_prefix'],project_data['teacher_number_of_previously_posted_projects'],project_data['price'],Y,test_size=0.10, random_state=15,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2qxOIRf9bFCe"
   },
   "outputs": [],
   "source": [
    "# Numerical input\n",
    "# Train\n",
    "train_posted=np.array(train_posted).reshape(-1,1)\n",
    "train_price=np.array(train_price).reshape(-1,1)\n",
    "train_num=np.hstack((train_posted,train_price))\n",
    "#Test\n",
    "test_posted=np.array(test_posted).reshape(-1,1)\n",
    "test_price=np.array(test_price).reshape(-1,1)\n",
    "test_num=np.hstack((test_posted,test_price))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3MFY6bBKXIL"
   },
   "outputs": [],
   "source": [
    " # prepare tokenizer\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-e1rTF45LOCZ"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lALxDbYZLgW2",
    "outputId": "87a792e9-d7ee-469e-83da-38a172b04f20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'students': 1,\n",
       " 'i': 2,\n",
       " 'school': 3,\n",
       " 'my': 4,\n",
       " 'learning': 5,\n",
       " 'classroom': 6,\n",
       " 'the': 7,\n",
       " 'not': 8,\n",
       " 'they': 9,\n",
       " 'learn': 10,\n",
       " 'help': 11,\n",
       " 'many': 12,\n",
       " 'nannan': 13,\n",
       " 'we': 14,\n",
       " 'need': 15,\n",
       " 'work': 16,\n",
       " 'reading': 17,\n",
       " 'use': 18,\n",
       " 'love': 19,\n",
       " 'day': 20,\n",
       " 'able': 21,\n",
       " 'come': 22,\n",
       " 'class': 23,\n",
       " 'would': 24,\n",
       " 'our': 25,\n",
       " 'technology': 26,\n",
       " 'skills': 27,\n",
       " 'also': 28,\n",
       " 'this': 29,\n",
       " 'year': 30,\n",
       " 'new': 31,\n",
       " 'books': 32,\n",
       " 'make': 33,\n",
       " 'want': 34,\n",
       " 'time': 35,\n",
       " 'student': 36,\n",
       " 'one': 37,\n",
       " 'these': 38,\n",
       " 'grade': 39,\n",
       " 'get': 40,\n",
       " 'math': 41,\n",
       " 'materials': 42,\n",
       " 'allow': 43,\n",
       " 'every': 44,\n",
       " 'children': 45,\n",
       " 'provide': 46,\n",
       " 'read': 47,\n",
       " 'world': 48,\n",
       " 'teach': 49,\n",
       " 'high': 50,\n",
       " 'project': 51,\n",
       " 'different': 52,\n",
       " 'like': 53,\n",
       " 'it': 54,\n",
       " 'best': 55,\n",
       " 'learners': 56,\n",
       " 'create': 57,\n",
       " 'needs': 58,\n",
       " 'way': 59,\n",
       " 'group': 60,\n",
       " 'education': 61,\n",
       " 'kids': 62,\n",
       " 'home': 63,\n",
       " 'free': 64,\n",
       " 'science': 65,\n",
       " 'well': 66,\n",
       " 'access': 67,\n",
       " 'language': 68,\n",
       " 'life': 69,\n",
       " 'using': 70,\n",
       " 'first': 71,\n",
       " 'give': 72,\n",
       " 'activities': 73,\n",
       " 'community': 74,\n",
       " 'opportunity': 75,\n",
       " 'teacher': 76,\n",
       " 'hard': 77,\n",
       " 'in': 78,\n",
       " 'working': 79,\n",
       " 'fun': 80,\n",
       " 'lunch': 81,\n",
       " 'small': 82,\n",
       " 'environment': 83,\n",
       " 'see': 84,\n",
       " 'hands': 85,\n",
       " 'supplies': 86,\n",
       " 'take': 87,\n",
       " 'level': 88,\n",
       " 'great': 89,\n",
       " 'excited': 90,\n",
       " 'low': 91,\n",
       " 'english': 92,\n",
       " 'used': 93,\n",
       " 'resources': 94,\n",
       " 'eager': 95,\n",
       " 'us': 96,\n",
       " 'experience': 97,\n",
       " 'daily': 98,\n",
       " 'with': 99,\n",
       " 'much': 100,\n",
       " 'become': 101,\n",
       " 'writing': 102,\n",
       " 'know': 103,\n",
       " 'diverse': 104,\n",
       " 'special': 105,\n",
       " 'as': 106,\n",
       " 'better': 107,\n",
       " 'support': 108,\n",
       " 'around': 109,\n",
       " 'families': 110,\n",
       " 'things': 111,\n",
       " 'seating': 112,\n",
       " 'title': 113,\n",
       " 'move': 114,\n",
       " 'even': 115,\n",
       " 'play': 116,\n",
       " 'place': 117,\n",
       " 'keep': 118,\n",
       " 'variety': 119,\n",
       " 'focus': 120,\n",
       " 'always': 121,\n",
       " 'book': 122,\n",
       " 'graders': 123,\n",
       " 'art': 124,\n",
       " 'successful': 125,\n",
       " 'challenges': 126,\n",
       " 'opportunities': 127,\n",
       " 'program': 128,\n",
       " 'experiences': 129,\n",
       " 'important': 130,\n",
       " 'receive': 131,\n",
       " 'poverty': 132,\n",
       " 'together': 133,\n",
       " 'income': 134,\n",
       " 'practice': 135,\n",
       " 'projects': 136,\n",
       " 'feel': 137,\n",
       " 'area': 138,\n",
       " 'academic': 139,\n",
       " 'backgrounds': 140,\n",
       " 'ready': 141,\n",
       " 'kindergarten': 142,\n",
       " 'often': 143,\n",
       " 'creative': 144,\n",
       " 'goal': 145,\n",
       " 'ways': 146,\n",
       " 'teaching': 147,\n",
       " 'active': 148,\n",
       " 'reduced': 149,\n",
       " 'tools': 150,\n",
       " 'future': 151,\n",
       " 'enjoy': 152,\n",
       " 'explore': 153,\n",
       " 'years': 154,\n",
       " 'room': 155,\n",
       " 'build': 156,\n",
       " 'amazing': 157,\n",
       " 'order': 158,\n",
       " 'research': 159,\n",
       " 'social': 160,\n",
       " 'lives': 161,\n",
       " 'parents': 162,\n",
       " 'part': 163,\n",
       " 'go': 164,\n",
       " 'music': 165,\n",
       " 'library': 166,\n",
       " 'throughout': 167,\n",
       " 'no': 168,\n",
       " 'teachers': 169,\n",
       " 'may': 170,\n",
       " 'games': 171,\n",
       " 'district': 172,\n",
       " 'a': 173,\n",
       " 'full': 174,\n",
       " 'sit': 175,\n",
       " 'chairs': 176,\n",
       " 'grow': 177,\n",
       " 'by': 178,\n",
       " 'having': 179,\n",
       " 'success': 180,\n",
       " 'engaged': 181,\n",
       " 'little': 182,\n",
       " 'readers': 183,\n",
       " 'without': 184,\n",
       " '1': 185,\n",
       " 'child': 186,\n",
       " 'find': 187,\n",
       " 'set': 188,\n",
       " 'lessons': 189,\n",
       " 'live': 190,\n",
       " 'computer': 191,\n",
       " 'second': 192,\n",
       " 'improve': 193,\n",
       " 'knowledge': 194,\n",
       " 'share': 195,\n",
       " 'others': 196,\n",
       " 'however': 197,\n",
       " 'safe': 198,\n",
       " 'instruction': 199,\n",
       " 'engaging': 200,\n",
       " 'face': 201,\n",
       " 'could': 202,\n",
       " 'groups': 203,\n",
       " 'meet': 204,\n",
       " 'all': 205,\n",
       " 'literacy': 206,\n",
       " 'outside': 207,\n",
       " 'develop': 208,\n",
       " 'everyday': 209,\n",
       " 'building': 210,\n",
       " 'two': 211,\n",
       " 'ability': 212,\n",
       " 'still': 213,\n",
       " 'young': 214,\n",
       " 'when': 215,\n",
       " 'increase': 216,\n",
       " 'levels': 217,\n",
       " 'based': 218,\n",
       " 'center': 219,\n",
       " 'some': 220,\n",
       " 'positive': 221,\n",
       " 'chromebooks': 222,\n",
       " 'limited': 223,\n",
       " 'comfortable': 224,\n",
       " 'needed': 225,\n",
       " 'population': 226,\n",
       " 'various': 227,\n",
       " 'items': 228,\n",
       " 'family': 229,\n",
       " 'ipads': 230,\n",
       " 'movement': 231,\n",
       " 'wonderful': 232,\n",
       " 'try': 233,\n",
       " 'most': 234,\n",
       " 'classes': 235,\n",
       " 'space': 236,\n",
       " 'engage': 237,\n",
       " 'problem': 238,\n",
       " 'believe': 239,\n",
       " 'curriculum': 240,\n",
       " 'bring': 241,\n",
       " 'show': 242,\n",
       " 'lot': 243,\n",
       " 'continue': 244,\n",
       " 'energy': 245,\n",
       " 'currently': 246,\n",
       " 'educational': 247,\n",
       " 'real': 248,\n",
       " 'flexible': 249,\n",
       " 'benefit': 250,\n",
       " 'despite': 251,\n",
       " 'long': 252,\n",
       " 'ipad': 253,\n",
       " 'making': 254,\n",
       " 'concepts': 255,\n",
       " 'possible': 256,\n",
       " 'something': 257,\n",
       " 'another': 258,\n",
       " 'words': 259,\n",
       " 'difficult': 260,\n",
       " 'physical': 261,\n",
       " 'good': 262,\n",
       " 'paper': 263,\n",
       " 'thinking': 264,\n",
       " 'stem': 265,\n",
       " 'computers': 266,\n",
       " 'middle': 267,\n",
       " 'succeed': 268,\n",
       " 'basic': 269,\n",
       " 'goals': 270,\n",
       " 'struggle': 271,\n",
       " 'providing': 272,\n",
       " 'each': 273,\n",
       " 'really': 274,\n",
       " 'areas': 275,\n",
       " 'college': 276,\n",
       " 'large': 277,\n",
       " 'there': 278,\n",
       " 'creating': 279,\n",
       " 'city': 280,\n",
       " 'addition': 281,\n",
       " 'complete': 282,\n",
       " 'available': 283,\n",
       " 'options': 284,\n",
       " 'unique': 285,\n",
       " 'several': 286,\n",
       " 'write': 287,\n",
       " 'elementary': 288,\n",
       " 'choose': 289,\n",
       " 'understand': 290,\n",
       " 'allows': 291,\n",
       " 'hope': 292,\n",
       " 'challenge': 293,\n",
       " 'enough': 294,\n",
       " 'within': 295,\n",
       " 'stay': 296,\n",
       " 'never': 297,\n",
       " 'equipment': 298,\n",
       " 'disabilities': 299,\n",
       " 'homes': 300,\n",
       " 'sitting': 301,\n",
       " 'think': 302,\n",
       " 'breakfast': 303,\n",
       " 'for': 304,\n",
       " 'healthy': 305,\n",
       " 'understanding': 306,\n",
       " 'stories': 307,\n",
       " 'activity': 308,\n",
       " 'arts': 309,\n",
       " 'times': 310,\n",
       " 'exciting': 311,\n",
       " 'right': 312,\n",
       " 'given': 313,\n",
       " 'reach': 314,\n",
       " 'enhance': 315,\n",
       " 'look': 316,\n",
       " 'individual': 317,\n",
       " '5': 318,\n",
       " 'old': 319,\n",
       " 'majority': 320,\n",
       " 'chance': 321,\n",
       " 'due': 322,\n",
       " 'start': 323,\n",
       " 'centers': 324,\n",
       " 'encourage': 325,\n",
       " 'self': 326,\n",
       " 'team': 327,\n",
       " 'interest': 328,\n",
       " 'information': 329,\n",
       " 'ideas': 330,\n",
       " 'schools': 331,\n",
       " 'makes': 332,\n",
       " 'range': 333,\n",
       " 'getting': 334,\n",
       " 'independent': 335,\n",
       " 'potential': 336,\n",
       " 'programs': 337,\n",
       " 'means': 338,\n",
       " 'whole': 339,\n",
       " 'stools': 340,\n",
       " 'people': 341,\n",
       " 'looking': 342,\n",
       " 'peers': 343,\n",
       " 'helps': 344,\n",
       " 'deserve': 345,\n",
       " 'requesting': 346,\n",
       " 'helping': 347,\n",
       " 'necessary': 348,\n",
       " 'change': 349,\n",
       " 'located': 350,\n",
       " 'last': 351,\n",
       " 'age': 352,\n",
       " 'k': 353,\n",
       " 'going': 354,\n",
       " 'strive': 355,\n",
       " 'studies': 356,\n",
       " 'coming': 357,\n",
       " 'third': 358,\n",
       " 'problems': 359,\n",
       " 'motivated': 360,\n",
       " 'lack': 361,\n",
       " 'classrooms': 362,\n",
       " 'interactive': 363,\n",
       " 'everything': 364,\n",
       " 'please': 365,\n",
       " 'achieve': 366,\n",
       " 'rural': 367,\n",
       " 'participate': 368,\n",
       " 'next': 369,\n",
       " 'put': 370,\n",
       " 'moving': 371,\n",
       " 'focused': 372,\n",
       " 'extra': 373,\n",
       " 'process': 374,\n",
       " 'listening': 375,\n",
       " 'made': 376,\n",
       " 'if': 377,\n",
       " 'attention': 378,\n",
       " 'difference': 379,\n",
       " 'truly': 380,\n",
       " 'wide': 381,\n",
       " 'since': 382,\n",
       " 'energetic': 383,\n",
       " 'growth': 384,\n",
       " 'back': 385,\n",
       " 'attend': 386,\n",
       " 'thank': 387,\n",
       " 'desks': 388,\n",
       " 'balls': 389,\n",
       " 'critical': 390,\n",
       " 'economic': 391,\n",
       " 'basis': 392,\n",
       " 'creativity': 393,\n",
       " 'current': 394,\n",
       " 'especially': 395,\n",
       " 'their': 396,\n",
       " 'food': 397,\n",
       " 'headphones': 398,\n",
       " 'giving': 399,\n",
       " 'walk': 400,\n",
       " '3': 401,\n",
       " 'minds': 402,\n",
       " 'quality': 403,\n",
       " 'socioeconomic': 404,\n",
       " 'prepare': 405,\n",
       " 'online': 406,\n",
       " 'table': 407,\n",
       " 'abilities': 408,\n",
       " 'big': 409,\n",
       " 'century': 410,\n",
       " 'choice': 411,\n",
       " 'grades': 412,\n",
       " 'along': 413,\n",
       " 'setting': 414,\n",
       " 'tablets': 415,\n",
       " '100': 416,\n",
       " 'neighborhood': 417,\n",
       " 'chair': 418,\n",
       " 'donation': 419,\n",
       " 'asking': 420,\n",
       " 'wobble': 421,\n",
       " 'end': 422,\n",
       " 'apps': 423,\n",
       " 'yet': 424,\n",
       " 'standards': 425,\n",
       " 'multiple': 426,\n",
       " 'week': 427,\n",
       " 'state': 428,\n",
       " 'core': 429,\n",
       " 'playing': 430,\n",
       " 'sure': 431,\n",
       " 'today': 432,\n",
       " 'curious': 433,\n",
       " 'personal': 434,\n",
       " 'job': 435,\n",
       " 'text': 436,\n",
       " '2': 437,\n",
       " 'ever': 438,\n",
       " 'sensory': 439,\n",
       " '21st': 440,\n",
       " 'public': 441,\n",
       " 'trying': 442,\n",
       " 'number': 443,\n",
       " 'meaningful': 444,\n",
       " 'everyone': 445,\n",
       " 'growing': 446,\n",
       " 'including': 447,\n",
       " 'visual': 448,\n",
       " 'sometimes': 449,\n",
       " 'already': 450,\n",
       " 'vocabulary': 451,\n",
       " 'story': 452,\n",
       " 'solving': 453,\n",
       " 'your': 454,\n",
       " 'engineering': 455,\n",
       " 'cannot': 456,\n",
       " 'beyond': 457,\n",
       " 'care': 458,\n",
       " 'while': 459,\n",
       " 'scholars': 460,\n",
       " 'donations': 461,\n",
       " 'learned': 462,\n",
       " 'literature': 463,\n",
       " 'content': 464,\n",
       " 'essential': 465,\n",
       " 'choices': 466,\n",
       " 'three': 467,\n",
       " 'topics': 468,\n",
       " 'single': 469,\n",
       " '5th': 470,\n",
       " 'task': 471,\n",
       " 'ensure': 472,\n",
       " 'hand': 473,\n",
       " 'add': 474,\n",
       " 'inspire': 475,\n",
       " 'spanish': 476,\n",
       " 'taught': 477,\n",
       " 'offer': 478,\n",
       " 'desire': 479,\n",
       " 'tool': 480,\n",
       " 'open': 481,\n",
       " 'must': 482,\n",
       " 'comprehension': 483,\n",
       " 'solve': 484,\n",
       " 'urban': 485,\n",
       " 'let': 486,\n",
       " 'common': 487,\n",
       " 'listen': 488,\n",
       " 'spend': 489,\n",
       " 'strong': 490,\n",
       " 'requested': 491,\n",
       " 'questions': 492,\n",
       " 'begin': 493,\n",
       " 'design': 494,\n",
       " 'challenging': 495,\n",
       " 'confidence': 496,\n",
       " 'greatly': 497,\n",
       " 'ask': 498,\n",
       " 'digital': 499,\n",
       " 'allowing': 500,\n",
       " 'extremely': 501,\n",
       " 'taking': 502,\n",
       " 'speak': 503,\n",
       " 'desk': 504,\n",
       " 'constantly': 505,\n",
       " 'early': 506,\n",
       " 'morning': 507,\n",
       " 'funding': 508,\n",
       " 'lesson': 509,\n",
       " 'forward': 510,\n",
       " 'at': 511,\n",
       " 'parent': 512,\n",
       " 'living': 513,\n",
       " 'provides': 514,\n",
       " 'skill': 515,\n",
       " 'bright': 516,\n",
       " 'unfortunately': 517,\n",
       " '6': 518,\n",
       " 'comes': 519,\n",
       " 'excitement': 520,\n",
       " 'sense': 521,\n",
       " 'plan': 522,\n",
       " '4': 523,\n",
       " 'impact': 524,\n",
       " 'struggling': 525,\n",
       " 'money': 526,\n",
       " 'emotional': 527,\n",
       " 'board': 528,\n",
       " 'pencils': 529,\n",
       " 'recess': 530,\n",
       " 'autism': 531,\n",
       " 'lab': 532,\n",
       " 'thing': 533,\n",
       " 'independently': 534,\n",
       " 'color': 535,\n",
       " 'study': 536,\n",
       " 'organized': 537,\n",
       " 'traditional': 538,\n",
       " 'though': 539,\n",
       " 'additional': 540,\n",
       " 'seats': 541,\n",
       " 'hear': 542,\n",
       " 'word': 543,\n",
       " 'non': 544,\n",
       " 'floor': 545,\n",
       " 'engagement': 546,\n",
       " 'although': 547,\n",
       " 'beginning': 548,\n",
       " 'gain': 549,\n",
       " 'health': 550,\n",
       " 'include': 551,\n",
       " 'asked': 552,\n",
       " 'past': 553,\n",
       " 'what': 554,\n",
       " 'coding': 555,\n",
       " 'body': 556,\n",
       " 'pre': 557,\n",
       " 'exercise': 558,\n",
       " 'game': 559,\n",
       " 'foster': 560,\n",
       " 'communication': 561,\n",
       " 'carpet': 562,\n",
       " 'kind': 563,\n",
       " 'serve': 564,\n",
       " 'imagine': 565,\n",
       " 'minutes': 566,\n",
       " 'higher': 567,\n",
       " 'control': 568,\n",
       " 'issues': 569,\n",
       " 'rug': 570,\n",
       " 'enthusiastic': 571,\n",
       " 'development': 572,\n",
       " 'anything': 573,\n",
       " 'assignments': 574,\n",
       " 'american': 575,\n",
       " 'easily': 576,\n",
       " 'days': 577,\n",
       " 'history': 578,\n",
       " 'printer': 579,\n",
       " 'career': 580,\n",
       " 'brain': 581,\n",
       " 'huge': 582,\n",
       " 'bodies': 583,\n",
       " 'alternative': 584,\n",
       " 'appropriate': 585,\n",
       " 'specific': 586,\n",
       " 'simple': 587,\n",
       " 'easy': 588,\n",
       " 'four': 589,\n",
       " 'behavior': 590,\n",
       " 'tables': 591,\n",
       " 'fifth': 592,\n",
       " 'works': 593,\n",
       " 'less': 594,\n",
       " 'system': 595,\n",
       " 'academically': 596,\n",
       " 'faced': 597,\n",
       " 'print': 598,\n",
       " 'require': 599,\n",
       " 'instead': 600,\n",
       " 'google': 601,\n",
       " 'material': 602,\n",
       " 'texts': 603,\n",
       " 'qualify': 604,\n",
       " 'five': 605,\n",
       " 'enter': 606,\n",
       " 'instruments': 607,\n",
       " 'promote': 608,\n",
       " 'staff': 609,\n",
       " 'type': 610,\n",
       " 'away': 611,\n",
       " 'cultures': 612,\n",
       " 'background': 613,\n",
       " 'subject': 614,\n",
       " 'to': 615,\n",
       " 'fluency': 616,\n",
       " 'turn': 617,\n",
       " 'close': 618,\n",
       " 'videos': 619,\n",
       " 'ball': 620,\n",
       " 'becoming': 621,\n",
       " 'wiggle': 622,\n",
       " 'sports': 623,\n",
       " 'budget': 624,\n",
       " '8': 625,\n",
       " 'entire': 626,\n",
       " 'fourth': 627,\n",
       " 'proud': 628,\n",
       " 'pictures': 629,\n",
       " 'express': 630,\n",
       " 'styles': 631,\n",
       " 'through': 632,\n",
       " 'test': 633,\n",
       " 'languages': 634,\n",
       " 'store': 635,\n",
       " 'boards': 636,\n",
       " 'provided': 637,\n",
       " 'therefore': 638,\n",
       " 'types': 639,\n",
       " 'motor': 640,\n",
       " 'that': 641,\n",
       " 'incorporate': 642,\n",
       " 'favorite': 643,\n",
       " 'filled': 644,\n",
       " '4th': 645,\n",
       " 'markers': 646,\n",
       " 'stand': 647,\n",
       " 'yoga': 648,\n",
       " 'utilize': 649,\n",
       " 'purchase': 650,\n",
       " 'amount': 651,\n",
       " 'being': 652,\n",
       " 'water': 653,\n",
       " 'letters': 654,\n",
       " 'strategies': 655,\n",
       " 'percent': 656,\n",
       " 'manipulatives': 657,\n",
       " 'passion': 658,\n",
       " 'found': 659,\n",
       " 'price': 660,\n",
       " 'girls': 661,\n",
       " 'events': 662,\n",
       " 'pencil': 663,\n",
       " 'field': 664,\n",
       " 'happy': 665,\n",
       " 'internet': 666,\n",
       " 'receiving': 667,\n",
       " 'caring': 668,\n",
       " 'collaborate': 669,\n",
       " '3rd': 670,\n",
       " 'subjects': 671,\n",
       " 'progress': 672,\n",
       " 'collaboration': 673,\n",
       " 'regular': 674,\n",
       " 'you': 675,\n",
       " 'town': 676,\n",
       " 'stations': 677,\n",
       " 'general': 678,\n",
       " 'achievement': 679,\n",
       " 'involved': 680,\n",
       " 'interested': 681,\n",
       " 'key': 682,\n",
       " 'developing': 683,\n",
       " 'matter': 684,\n",
       " 'resource': 685,\n",
       " 'academics': 686,\n",
       " 'expand': 687,\n",
       " 'seen': 688,\n",
       " 'heart': 689,\n",
       " 'enable': 690,\n",
       " 'highly': 691,\n",
       " 'friends': 692,\n",
       " 'loving': 693,\n",
       " 'because': 694,\n",
       " 'inspired': 695,\n",
       " 'say': 696,\n",
       " 'gifted': 697,\n",
       " 'culture': 698,\n",
       " 'interests': 699,\n",
       " 'thrive': 700,\n",
       " 'assist': 701,\n",
       " 'lots': 702,\n",
       " 'unit': 703,\n",
       " 'balance': 704,\n",
       " 'typical': 705,\n",
       " 'pride': 706,\n",
       " 'gives': 707,\n",
       " 'fiction': 708,\n",
       " 'tell': 709,\n",
       " 'members': 710,\n",
       " 'steam': 711,\n",
       " 'status': 712,\n",
       " 'leaders': 713,\n",
       " 'inner': 714,\n",
       " 'tasks': 715,\n",
       " 'exposed': 716,\n",
       " 'devices': 717,\n",
       " 'half': 718,\n",
       " 'etc': 719,\n",
       " 'fitness': 720,\n",
       " 'faces': 721,\n",
       " 'club': 722,\n",
       " 'station': 723,\n",
       " 'foundation': 724,\n",
       " 'towards': 725,\n",
       " 'seat': 726,\n",
       " 'fit': 727,\n",
       " 'afford': 728,\n",
       " '6th': 729,\n",
       " 'joy': 730,\n",
       " 'but': 731,\n",
       " 'awesome': 732,\n",
       " 'exposure': 733,\n",
       " 'wait': 734,\n",
       " '10': 735,\n",
       " 'light': 736,\n",
       " 'kits': 737,\n",
       " 'discover': 738,\n",
       " '20': 739,\n",
       " 'interact': 740,\n",
       " 'serves': 741,\n",
       " 'connect': 742,\n",
       " '2nd': 743,\n",
       " 'inquisitive': 744,\n",
       " 'across': 745,\n",
       " 'almost': 746,\n",
       " 'so': 747,\n",
       " 'interesting': 748,\n",
       " 'individuals': 749,\n",
       " 'places': 750,\n",
       " 'situations': 751,\n",
       " 'created': 752,\n",
       " 'hold': 753,\n",
       " 'perfect': 754,\n",
       " 'idea': 755,\n",
       " 'step': 756,\n",
       " 'novels': 757,\n",
       " 'rich': 758,\n",
       " 'mathematics': 759,\n",
       " 'motivation': 760,\n",
       " '8th': 761,\n",
       " 'during': 762,\n",
       " 'country': 763,\n",
       " 'far': 764,\n",
       " 'run': 765,\n",
       " 'least': 766,\n",
       " 'smart': 767,\n",
       " 'willing': 768,\n",
       " 'done': 769,\n",
       " 'media': 770,\n",
       " 'video': 771,\n",
       " 'expectations': 772,\n",
       " 'camera': 773,\n",
       " 'fine': 774,\n",
       " 'said': 775,\n",
       " 'prepared': 776,\n",
       " 'inside': 777,\n",
       " 'remember': 778,\n",
       " 'watch': 779,\n",
       " '60': 780,\n",
       " 'easier': 781,\n",
       " 'communicate': 782,\n",
       " 'adults': 783,\n",
       " 'break': 784,\n",
       " 'sharing': 785,\n",
       " 'quickly': 786,\n",
       " 'sets': 787,\n",
       " 'model': 788,\n",
       " 'option': 789,\n",
       " 'course': 790,\n",
       " 'society': 791,\n",
       " 'door': 792,\n",
       " 'motivate': 793,\n",
       " 'seeing': 794,\n",
       " 'data': 795,\n",
       " 'importance': 796,\n",
       " 'speaking': 797,\n",
       " 'band': 798,\n",
       " 'longer': 799,\n",
       " 'simply': 800,\n",
       " 'snacks': 801,\n",
       " 'started': 802,\n",
       " 'mind': 803,\n",
       " 'cultural': 804,\n",
       " 'numbers': 805,\n",
       " 'diversity': 806,\n",
       " 'rather': 807,\n",
       " 'curiosity': 808,\n",
       " 'boys': 809,\n",
       " 'sounds': 810,\n",
       " 'lead': 811,\n",
       " 'households': 812,\n",
       " 'obstacles': 813,\n",
       " 'and': 814,\n",
       " 'connections': 815,\n",
       " 'beautiful': 816,\n",
       " 'stability': 817,\n",
       " 'present': 818,\n",
       " 'thinkers': 819,\n",
       " 'fully': 820,\n",
       " 'ones': 821,\n",
       " 'laptops': 822,\n",
       " 'loved': 823,\n",
       " 'after': 824,\n",
       " 'responsibility': 825,\n",
       " 'donating': 826,\n",
       " 'olds': 827,\n",
       " 'appreciate': 828,\n",
       " 'includes': 829,\n",
       " 'track': 830,\n",
       " 'takes': 831,\n",
       " 'true': 832,\n",
       " 'writers': 833,\n",
       " 'behind': 834,\n",
       " 'perform': 835,\n",
       " 'hours': 836,\n",
       " 'hispanic': 837,\n",
       " 'recently': 838,\n",
       " 'standing': 839,\n",
       " '30': 840,\n",
       " 'might': 841,\n",
       " 'required': 842,\n",
       " 'apply': 843,\n",
       " 'actively': 844,\n",
       " 'guided': 845,\n",
       " 'productive': 846,\n",
       " 'white': 847,\n",
       " 'exploring': 848,\n",
       " 'meeting': 849,\n",
       " 'economically': 850,\n",
       " 'leave': 851,\n",
       " 'proper': 852,\n",
       " 'dreams': 853,\n",
       " 'power': 854,\n",
       " 'keeping': 855,\n",
       " 'overcome': 856,\n",
       " '7': 857,\n",
       " 'six': 858,\n",
       " 'effective': 859,\n",
       " 'lifelong': 860,\n",
       " 'innovative': 861,\n",
       " 'speech': 862,\n",
       " 'sound': 863,\n",
       " 'dedicated': 864,\n",
       " 'fact': 865,\n",
       " 'funds': 866,\n",
       " 'jobs': 867,\n",
       " 'dance': 868,\n",
       " 'garden': 869,\n",
       " 'changing': 870,\n",
       " 'supply': 871,\n",
       " 'letter': 872,\n",
       " 'hokki': 873,\n",
       " 'generous': 874,\n",
       " 'rate': 875,\n",
       " '90': 876,\n",
       " 'chromebook': 877,\n",
       " 'hungry': 878,\n",
       " 'african': 879,\n",
       " 'reader': 880,\n",
       " 'socio': 881,\n",
       " 'dry': 882,\n",
       " 'value': 883,\n",
       " 'rest': 884,\n",
       " 'dream': 885,\n",
       " 'smile': 886,\n",
       " 'challenged': 887,\n",
       " 'scientists': 888,\n",
       " 'form': 889,\n",
       " 'storage': 890,\n",
       " 'services': 891,\n",
       " 'responsible': 892,\n",
       " 'preschool': 893,\n",
       " 'notebooks': 894,\n",
       " 'campus': 895,\n",
       " 'novel': 896,\n",
       " 'laptop': 897,\n",
       " 'financial': 898,\n",
       " 'example': 899,\n",
       " 'collaborative': 900,\n",
       " 'careers': 901,\n",
       " 'happen': 902,\n",
       " 'classmates': 903,\n",
       " 'whether': 904,\n",
       " 'short': 905,\n",
       " '12': 906,\n",
       " 'display': 907,\n",
       " 'approximately': 908,\n",
       " 'lower': 909,\n",
       " 'journey': 910,\n",
       " 'adding': 911,\n",
       " 'local': 912,\n",
       " 'met': 913,\n",
       " 'struggles': 914,\n",
       " 'clean': 915,\n",
       " 'benefits': 916,\n",
       " 'push': 917,\n",
       " 'funded': 918,\n",
       " 'unable': 919,\n",
       " 'shows': 920,\n",
       " 'rigorous': 921,\n",
       " 'performance': 922,\n",
       " 'enthusiasm': 923,\n",
       " 'countries': 924,\n",
       " 'kiddos': 925,\n",
       " 'disadvantaged': 926,\n",
       " 'magazines': 927,\n",
       " 'hardships': 928,\n",
       " 'discuss': 929,\n",
       " 'gap': 930,\n",
       " 'consists': 931,\n",
       " 'pieces': 932,\n",
       " 'breaks': 933,\n",
       " 'robots': 934,\n",
       " 'osmo': 935,\n",
       " 'performing': 936,\n",
       " 'lunches': 937,\n",
       " 'document': 938,\n",
       " '25': 939,\n",
       " 'donors': 940,\n",
       " 'possibilities': 941,\n",
       " 'erase': 942,\n",
       " 'mini': 943,\n",
       " 'kit': 944,\n",
       " 'picture': 945,\n",
       " 'follow': 946,\n",
       " 'fall': 947,\n",
       " 'hoping': 948,\n",
       " 'testing': 949,\n",
       " 'shown': 950,\n",
       " 'code': 951,\n",
       " 'over': 952,\n",
       " 'sight': 953,\n",
       " 'box': 954,\n",
       " 'talk': 955,\n",
       " 'lost': 956,\n",
       " 'risk': 957,\n",
       " 'overall': 958,\n",
       " 'top': 959,\n",
       " 'focusing': 960,\n",
       " 'presentations': 961,\n",
       " 'how': 962,\n",
       " 'talented': 963,\n",
       " '3d': 964,\n",
       " 'incredible': 965,\n",
       " 'kid': 966,\n",
       " 'approach': 967,\n",
       " 'news': 968,\n",
       " 'reinforce': 969,\n",
       " '50': 970,\n",
       " 'from': 971,\n",
       " 'generation': 972,\n",
       " 'notes': 973,\n",
       " 'lucky': 974,\n",
       " 'greater': 975,\n",
       " 'ownership': 976,\n",
       " 'designed': 977,\n",
       " 'intervention': 978,\n",
       " 'imagination': 979,\n",
       " 'starting': 980,\n",
       " 'adhd': 981,\n",
       " 'written': 982,\n",
       " 'citizens': 983,\n",
       " 'confident': 984,\n",
       " 'character': 985,\n",
       " 'exploration': 986,\n",
       " 'robotics': 987,\n",
       " 'endless': 988,\n",
       " 'accomplish': 989,\n",
       " 'south': 990,\n",
       " 'highest': 991,\n",
       " 'valuable': 992,\n",
       " 'record': 993,\n",
       " 'bands': 994,\n",
       " 'stop': 995,\n",
       " 'fortunate': 996,\n",
       " 'eyes': 997,\n",
       " 'actually': 998,\n",
       " 'nothing': 999,\n",
       " 'finding': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lb2z1y3cLZLw"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "J_OOzwmQcwR_",
    "outputId": "0615e303-272d-42e3-fc0b-658749f12fd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54143"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhGvCJCCLmyq"
   },
   "outputs": [],
   "source": [
    "# Creating numbers for each word in the corpus\n",
    "train_encoded_docs = tokenizer.texts_to_sequences(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "1bxyEqfSL3N0",
    "outputId": "aa8eb72a-bf13-4954-d5c0-dca5ad13cbe1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encoded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830
    },
    "colab_type": "code",
    "id": "Blu8wYQhL8r6",
    "outputId": "a3ecf1d2-bae7-4ace-acaf-383840d63ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   25     1   119   140     9   104  2761    66  1295    78    50     3\n",
      "   437  2075     1   446    12     1    40   558  1060   235  1837  2406\n",
      "  1750   381   333   284    70    35  1060  1646   720  4022     9    95\n",
      "   148    53  1074   235   478  1060   128   511 34521   564   939   235\n",
      "     1  1135   427    23  1229    50  2281     1   185   416     1    49\n",
      "  1037    14   478   434   720   235  2301  1491   235  1523   720   235\n",
      "  1145  1491   235   278  4913     1     7   293  1000   308  3596    44\n",
      "    36  1473  5205  1060   414    12    52    73  2390  6493    44    36\n",
      "   187   658   231   720    29    51    11     1   156  6494  1145  4057\n",
      "  3507   496  2693   442    31   143   310   297  2093   126   205     1\n",
      "    34   125    70 34522  4400   994   674   392    43     1   156  1145\n",
      "   980  1140   242    71   473   270   913   800  4593   369 11247  4400\n",
      "   798    13     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "# Padding with max_length=600\n",
    "max_length = 600\n",
    "train_padded_docs = pad_sequences(train_encoded_docs, maxlen=max_length, padding='post')\n",
    "print(train_padded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXtgS7WlMMVj"
   },
   "outputs": [],
   "source": [
    "# Test text\n",
    "test_encoded_docs = tokenizer.texts_to_sequences(test_text)\n",
    "# Padding with max_length=600\n",
    "max_length = 600\n",
    "test_padded_docs = pad_sequences(test_encoded_docs, maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Xp2ObDdM0Re"
   },
   "outputs": [],
   "source": [
    "# Creating dict with 'word' as key and 'vector' as value for the key\n",
    "\n",
    "# Opening the glove vectors file and storing the file in 'f'\n",
    "import pickle\n",
    "with open('gdrive/My Drive/data/glove_vectors','rb') as f:\n",
    "    # Creating dict as model with 'word' as key and 'vector' as 300D vec for the key\n",
    "    model=pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FBX_QD5AUpfr"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words with vectors in training docs\n",
    "vocab_size=67959\n",
    "weight_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "  vector = model.get(word)\n",
    "  if vector is not None:\n",
    "\t\t weight_matrix[i] = vector \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "DOjGwFjTZgAN",
    "outputId": "9d12d559-f8c6-4f36-8e24-8a6cac1ae7f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define text model\n",
    "text_input = Input(shape=(600,), name='text_input')\n",
    "text_emb=(Embedding(input_dim=vocab_size,output_dim=300,weights=[weight_matrix],input_length=600,trainable=False))(text_input)\n",
    "text_lstm=(LSTM(250,return_sequences=True))(text_emb)\n",
    "text_flatten=(Flatten())(text_lstm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "_UrmBQHkPDot",
    "outputId": "c87c3067-33eb-4d12-aa61-580ef3aba83b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ak'"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating train school_state dictionary for the embedding layer\n",
    "cat_state = train_state.astype('category')\n",
    "d = dict(enumerate(cat_state.cat.categories))\n",
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrCD1QUiPDHH"
   },
   "outputs": [],
   "source": [
    "\n",
    "#swaping key to value\n",
    "school_state_dict=dict([(value,key) for key,value in d.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "hGkIZXy9PCi7",
    "outputId": "e1bcdfa6-49ac-4535-b510-a2fcdbe4d568"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school_state_dict['ak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "xgoVqcH89vRv",
    "outputId": "4ed74caa-ef7e-4855-f3c2-db099d734283"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school_state_dict['ga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "bb639pBKPA0x",
    "outputId": "9273af07-5d8c-4ccd-a992-02e20a31450c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_school_state=len(school_state_dict)\n",
    "vocab_school_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLy5YFqZ8taG"
   },
   "outputs": [],
   "source": [
    "encoded_state_value=cat_state.map(school_state_dict)\n",
    "encoded_train_state_value=encoded_state_value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "MZyhyDkBOBWr",
    "outputId": "44659801-3489-48d7-bff4-589dadeb9da7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  4, 25, ..., 40,  4, 32])"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapping school state test\n",
    "encoded_state_value=test_state.map(school_state_dict)\n",
    "encoded_test_state_value=encoded_state_value.values\n",
    "encoded_test_state_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ROqRjAgCsqC0"
   },
   "outputs": [],
   "source": [
    "# Define school_state keras model\n",
    "school_state_input=Input(shape=(1,))\n",
    "school_state_emb=(Embedding(vocab_school_state,output_dim=5,input_length=1,trainable=True))(school_state_input)\n",
    "school_state_flatten=Flatten()(school_state_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "563pg7OHOBMD"
   },
   "outputs": [],
   "source": [
    "# creating train grade dictionary for the embedding layer\n",
    "cat_grade = train_grade.astype('category')\n",
    "d = dict(enumerate(cat_grade.cat.categories))\n",
    "#swaping key to value\n",
    "grade_dict=dict([(value,key) for key,value in d.items()])\n",
    "#mapping train grade\n",
    "encoded_grade_value=cat_grade.map(grade_dict)\n",
    "encoded_train_grade_value=encoded_grade_value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sDJdJesOBE2"
   },
   "outputs": [],
   "source": [
    "#mapping test grade\n",
    "encoded_grade_value=test_grade.map(grade_dict)\n",
    "encoded_test_grade_value=encoded_grade_value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8bwJyaU-0JZ"
   },
   "outputs": [],
   "source": [
    "# Define  project_grade keras model\n",
    "grade_input=Input(shape=(1,))\n",
    "grade_emb=Embedding(len(grade_dict),output_dim=10,input_length=1,trainable=True)(grade_input)\n",
    "grade_flatten=Flatten()(grade_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__gn62-_puAB"
   },
   "outputs": [],
   "source": [
    "# converting 'clean_categories' to categorical feature and obtaining intergers for each category\n",
    "cat_categories = train_category.astype('category')\n",
    "d = dict(enumerate(cat_categories.cat.categories))\n",
    "#swaping key to value\n",
    "categories_dict=dict([(value,key) for key,value in d.items()])\n",
    "#mapping train clean category\n",
    "encoded_cat_value=cat_categories.map(categories_dict)\n",
    "encoded_train_category_value=encoded_cat_value.values\n",
    "#mapping test claen category\n",
    "encoded_cat_value=test_category.map(categories_dict)\n",
    "encoded_test_category_value=encoded_cat_value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k11c0hIeB_kf"
   },
   "outputs": [],
   "source": [
    "# Define category keras model\n",
    "category_input=Input(shape=(1,))\n",
    "category_emb=Embedding(len(categories_dict),output_dim=10,input_length=1,trainable=True)(category_input)\n",
    "category_flatten=Flatten()(category_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aod23P7xCZbg"
   },
   "outputs": [],
   "source": [
    "# converting 'clean_subcategories' to categorical feature and obtaining intergers for each category\n",
    "cat_subcategories = train_sub.astype('category')\n",
    "d = dict(enumerate(cat_subcategories.cat.categories))\n",
    "#swaping key to value\n",
    "subcategories_dict=dict([(value,key) for key,value in d.items()])\n",
    "#mapping train clean category\n",
    "encoded_subcat_value=cat_subcategories.map(subcategories_dict)\n",
    "encoded_train_subcategory_value=encoded_subcat_value.values\n",
    "#mapping test clean subcategory\n",
    "encoded_subcat_value=test_sub.map(subcategories_dict)\n",
    "encoded_test_subcategory_value=encoded_subcat_value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhXPffjeCtb9"
   },
   "outputs": [],
   "source": [
    "# Define subcategory keras model\n",
    "subcategory_input=Input(shape=(1,))\n",
    "subcategory_emb=Embedding(len(subcategories_dict),output_dim=10,input_length=1,trainable=True)(subcategory_input)\n",
    "subcategory_flatten=Flatten()(subcategory_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60dncrKxq9DX"
   },
   "outputs": [],
   "source": [
    "# teacher prefix category\n",
    "cat_teacher = train_teacher.astype('category')\n",
    "d = dict(enumerate(cat_teacher.cat.categories))\n",
    "#swaping key to value\n",
    "teacher_dict=dict([(value,key) for key,value in d.items()])\n",
    "#mapping train teacher prefix\n",
    "encoded_teacher_value=cat_teacher.map(teacher_dict)\n",
    "encoded_train_teacher_value=encoded_teacher_value.values\n",
    "#mapping test teacher prefix\n",
    "encoded_teacher_value=test_teacher.map(teacher_dict)\n",
    "encoded_test_teacher_value=encoded_teacher_value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ENkhulUPrUXJ"
   },
   "outputs": [],
   "source": [
    "# Define teacher prefix keras model\n",
    "teacher_input=Input(shape=(1,))\n",
    "teacher_emb=Embedding(len(teacher_dict),output_dim=10,input_length=1,trainable=True)(teacher_input)\n",
    "teacher_flatten=Flatten()(teacher_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdYmLOq3YupY"
   },
   "outputs": [],
   "source": [
    "# numerical input keras model\n",
    "numerical_input=Input(shape=(2,))\n",
    "numerical_input_flatten=Dense(units=1,activation='relu',kernel_initializer='glorot_uniform')(numerical_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bd-E7hmTbiAd"
   },
   "outputs": [],
   "source": [
    "combined=concatenate([text_flatten,school_state_flatten,grade_flatten,category_flatten,subcategory_flatten,teacher_flatten,numerical_input_flatten])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "W-Kxshpgc-mB",
    "outputId": "7967d1a3-924b-4d97-9675-895e78ac0b89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# After combining layers\n",
    "den1=Dense(units=500,activation='relu',kernel_initializer='glorot_uniform')(combined)\n",
    "dropout1=Dropout(0.3)(den1)\n",
    "den2=Dense(units=250,activation='relu',kernel_initializer='glorot_uniform')(dropout1)\n",
    "bn1=BatchNormalization()(den2)\n",
    "den3=Dense(units=100,activation='relu',kernel_initializer='glorot_uniform')(bn1)\n",
    "den4=Dense(units=50,activation='relu',kernel_initializer='glorot_uniform')(den3)\n",
    "softmax_output=Dense(units=2,activation='softmax')(den4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7beNh08fcGb"
   },
   "outputs": [],
   "source": [
    "model1=Model(inputs=[text_input,school_state_input,grade_input,category_input,subcategory_input,teacher_input,numerical_input],outputs=[softmax_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9xY_uMwSx5in"
   },
   "outputs": [],
   "source": [
    "# One hot encoding 'y'\n",
    "encoder=OneHotEncoder()\n",
    "y_train_ohe=encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_ohe=encoder.transform(y_test.reshape(-1, 1))\n",
    "y_train_ohe=y_train_ohe.toarray()\n",
    "y_test_ohe=y_test_ohe.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "zaGKEd2Bwgzp",
    "outputId": "cd82f4d2-ac46-455a-9bb2-c802df7e58b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_ohe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-MMyFhcS0juo"
   },
   "outputs": [],
   "source": [
    "# Function to get 'auc' score\n",
    "def au_roc(y_true, y_pred):\n",
    "  try:\n",
    "      return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n",
    "  except ValueError:\n",
    "    pass\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "X9v6fj7M4XcY",
    "outputId": "f0ad9dc6-dace-442f-b2ce-8296986f7f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_input (InputLayer)         (None, 600)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 600, 300)     20387700    text_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 600, 250)     551000      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 5)         255         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 10)        40          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 10)        510         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 10)        3950        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 10)        50          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 150000)       0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 5)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 10)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 10)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 10)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 10)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            3           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 150046)       0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 500)          75023500    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 250)          125250      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 250)          1000        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          25100       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50)           5050        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            102         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 96,123,510\n",
      "Trainable params: 75,735,310\n",
      "Non-trainable params: 20,388,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j8T35uIB8gEb"
   },
   "source": [
    "# <center> model1 architecture-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "E-Qn9I1Cf9jw",
    "outputId": "045ef452-66fa-4046-ca61-db6281299ccb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 98323 samples, validate on 10925 samples\n",
      "Epoch 1/1\n",
      "98323/98323 [==============================] - 503s 5ms/step - loss: 0.2008 - acc: 0.9223 - au_roc: 0.9437 - val_loss: 0.6233 - val_acc: 0.8353 - val_au_roc: 0.7094\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.92231, saving model to gdrive/My Drive/data/weights_1/cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea37215eb8>"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the latest weights)\n",
    "model1.load_weights(\"gdrive/My Drive/data/weights_1/cp.ckpt\")\n",
    "rms=keras.optimizers.RMSprop(lr=0.01, rho=0.9)\n",
    "# compiling the model\n",
    "model1.compile(optimizer=rms,loss='categorical_crossentropy',metrics=['accuracy',au_roc])\n",
    "model1.fit([train_padded_docs,encoded_train_state_value,encoded_train_grade_value,encoded_train_category_value,encoded_train_subcategory_value,encoded_train_teacher_value,\n",
    "            train_num],y_train_ohe,validation_data=([test_padded_docs,encoded_test_state_value,encoded_test_grade_value,encoded_test_category_value,\n",
    "                                                                    encoded_test_subcategory_value,encoded_test_teacher_value,test_num],y_test_ohe),epochs=1,batch_size=300,\n",
    "            callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIrOQWF99XZZ"
   },
   "source": [
    "# validation auc is 0.7094. So trying with ADAM optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8oHDFsRU9Hqc"
   },
   "source": [
    "# <center> ADAM optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "id": "HmZpYnmX76gS",
    "outputId": "5d4c775a-5566-4087-daa1-e844f22d6625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98323 samples, validate on 10925 samples\n",
      "Epoch 1/1\n",
      "98323/98323 [==============================] - 532s 5ms/step - loss: 0.0122 - acc: 0.9958 - au_roc: 0.9997 - val_loss: 1.3705 - val_acc: 0.8493 - val_au_roc: 0.6848\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.99581, saving model to gdrive/My Drive/data/weights_1/adam.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e11d78e10>"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model1.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy',au_roc])\n",
    "\n",
    "# check point path\n",
    "checkpoint_path_3 = \"gdrive/My Drive/data/weights_1/adam.ckpt\"\n",
    "\n",
    "# Create checkpoint callback and store the best weights alone, discard updating the weights if the 'acc' does not improve\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path_3,monitor='acc',\n",
    "                                                 save_weights_only=True, save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model1.load_weights('gdrive/My Drive/data/weights_1/adam.ckpt')\n",
    "model1.fit([train_padded_docs,encoded_train_state_value,encoded_train_grade_value,encoded_train_category_value,encoded_train_subcategory_value,\n",
    "            encoded_train_teacher_value,train_num],y_train_ohe,validation_data=([test_padded_docs,encoded_test_state_value,encoded_test_grade_value,\n",
    "           encoded_test_category_value,encoded_test_subcategory_value,encoded_test_teacher_value,test_num],y_test_ohe)\n",
    "           ,epochs=1,batch_size=300,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fyDuhiNjB-4S"
   },
   "source": [
    "# validation auc is less than 0.70 for adam optimizer. So changing the architecture of model1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8O0UfzCfdIu7"
   },
   "source": [
    "# <center> model 1 architecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8RspAyf3dDSy"
   },
   "outputs": [],
   "source": [
    "# After combining layers\n",
    "den1=Dense(units=300,activation='relu',kernel_initializer='glorot_uniform')(combined)\n",
    "dropout1=Dropout(0.3)(den1)\n",
    "den2=Dense(units=100,activation='relu',kernel_initializer='glorot_uniform')(dropout1)\n",
    "bn1=BatchNormalization()(den2)\n",
    "softmax_output=Dense(units=2,activation='softmax')(bn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryEkZtgUdSED"
   },
   "outputs": [],
   "source": [
    "model1=Model(inputs=[text_input,school_state_input,grade_input,category_input,subcategory_input,teacher_input,numerical_input],outputs=[softmax_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCoHUyMmdXc3"
   },
   "outputs": [],
   "source": [
    "# check point path\n",
    "checkpoint_path_2 = \"gdrive/My Drive/data/weights_1/arch3rms.ckpt\"\n",
    "# Create checkpoint callback\n",
    "\n",
    "# Create checkpoint callback and store the best weights alone, discard updating the weights if the 'acc' does not improve\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path_2,monitor='acc',\n",
    "                                                 save_weights_only=True, save_best_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "colab_type": "code",
    "id": "lGeWyn3ydekJ",
    "outputId": "7079856c-02c3-4714-c874-bb220689e928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98323 samples, validate on 10925 samples\n",
      "Epoch 1/15\n",
      "98323/98323 [==============================] - 483s 5ms/step - loss: 0.3881 - acc: 0.8379 - au_roc: 0.7704 - val_loss: 0.3852 - val_acc: 0.8416 - val_au_roc: 0.7445\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.83791, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 2/15\n",
      "98323/98323 [==============================] - 481s 5ms/step - loss: 0.2963 - acc: 0.8857 - au_roc: 0.8592 - val_loss: 0.4409 - val_acc: 0.8176 - val_au_roc: 0.7293\n",
      "\n",
      "Epoch 00002: acc improved from 0.83791 to 0.88570, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 3/15\n",
      "98323/98323 [==============================] - 482s 5ms/step - loss: 0.2553 - acc: 0.9037 - au_roc: 0.9014 - val_loss: 0.5079 - val_acc: 0.7972 - val_au_roc: 0.7112\n",
      "\n",
      "Epoch 00003: acc improved from 0.88570 to 0.90371, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 4/15\n",
      "98323/98323 [==============================] - 482s 5ms/step - loss: 0.2077 - acc: 0.9219 - au_roc: 0.9369 - val_loss: 0.5775 - val_acc: 0.7635 - val_au_roc: 0.6847\n",
      "\n",
      "Epoch 00004: acc improved from 0.90371 to 0.92190, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 5/15\n",
      "98323/98323 [==============================] - 482s 5ms/step - loss: 0.1594 - acc: 0.9401 - au_roc: 0.9634 - val_loss: 0.6188 - val_acc: 0.7941 - val_au_roc: 0.6815\n",
      "\n",
      "Epoch 00005: acc improved from 0.92190 to 0.94006, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 6/15\n",
      "98323/98323 [==============================] - 482s 5ms/step - loss: 0.1179 - acc: 0.9571 - au_roc: 0.9808 - val_loss: 0.8691 - val_acc: 0.7912 - val_au_roc: 0.7093\n",
      "\n",
      "Epoch 00006: acc improved from 0.94006 to 0.95712, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 7/15\n",
      "98323/98323 [==============================] - 485s 5ms/step - loss: 0.0854 - acc: 0.9706 - au_roc: 0.9894 - val_loss: 0.6951 - val_acc: 0.8276 - val_au_roc: 0.6920\n",
      "\n",
      "Epoch 00007: acc improved from 0.95712 to 0.97059, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 8/15\n",
      "98323/98323 [==============================] - 484s 5ms/step - loss: 0.0653 - acc: 0.9773 - au_roc: 0.9939 - val_loss: 0.6687 - val_acc: 0.8079 - val_au_roc: 0.6556\n",
      "\n",
      "Epoch 00008: acc improved from 0.97059 to 0.97728, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 9/15\n",
      "98323/98323 [==============================] - 481s 5ms/step - loss: 0.0512 - acc: 0.9822 - au_roc: 0.9961 - val_loss: 0.7852 - val_acc: 0.7906 - val_au_roc: 0.6659\n",
      "\n",
      "Epoch 00009: acc improved from 0.97728 to 0.98224, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 10/15\n",
      "98323/98323 [==============================] - 482s 5ms/step - loss: 0.0445 - acc: 0.9853 - au_roc: 0.9970 - val_loss: 1.0315 - val_acc: 0.8115 - val_au_roc: 0.6907\n",
      "\n",
      "Epoch 00010: acc improved from 0.98224 to 0.98529, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 11/15\n",
      "98323/98323 [==============================] - 482s 5ms/step - loss: 0.0402 - acc: 0.9869 - au_roc: 0.9971 - val_loss: 1.0548 - val_acc: 0.7789 - val_au_roc: 0.6817\n",
      "\n",
      "Epoch 00011: acc improved from 0.98529 to 0.98689, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 12/15\n",
      "98323/98323 [==============================] - 486s 5ms/step - loss: 0.0356 - acc: 0.9884 - au_roc: 0.9978 - val_loss: 1.1287 - val_acc: 0.7519 - val_au_roc: 0.6869\n",
      "\n",
      "Epoch 00012: acc improved from 0.98689 to 0.98845, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 13/15\n",
      " 7200/98323 [=>............................] - ETA: 7:13 - loss: 0.0225 - acc: 0.9938 - au_roc: 0.9984"
     ]
    }
   ],
   "source": [
    "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
    "# compiling the model\n",
    "model1.compile(optimizer=rms,loss='categorical_crossentropy',metrics=['accuracy',au_roc])\n",
    "model1.fit([train_padded_docs,encoded_train_state_value,encoded_train_grade_value,encoded_train_category_value,encoded_train_subcategory_value,encoded_train_teacher_value,\n",
    "            train_num],y_train_ohe,validation_data=([test_padded_docs,encoded_test_state_value,encoded_test_grade_value,encoded_test_category_value,\n",
    "                                                                    encoded_test_subcategory_value,encoded_test_teacher_value,test_num],y_test_ohe),epochs=15,batch_size=300,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tbGO-7ht_LOR"
   },
   "source": [
    "# In many epoch we get validation auc greater than 0.70, but not greater than 0.75. So trying with 'LEAKY RELU'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_eY64EcGI8m"
   },
   "source": [
    "# <center> model 1 architecture 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ru7BONjRGWIU"
   },
   "outputs": [],
   "source": [
    "# After combining layers\n",
    "leaky_relu=keras.layers.LeakyReLU(alpha=0.3)\n",
    "den1=Dense(units=300,activation=leaky_relu,kernel_initializer='glorot_uniform')(combined)\n",
    "dropout1=Dropout(0.3)(den1)\n",
    "den2=Dense(units=100,activation=leaky_relu,kernel_initializer='glorot_uniform')(dropout1)\n",
    "bn1=BatchNormalization()(den2)\n",
    "softmax_output=Dense(units=2,activation='softmax')(bn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C33YrdiVGWIj"
   },
   "outputs": [],
   "source": [
    "model1=Model(inputs=[text_input,school_state_input,grade_input,category_input,subcategory_input,teacher_input,numerical_input],outputs=[softmax_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPwyBgszGWIt"
   },
   "outputs": [],
   "source": [
    "# check point path\n",
    "checkpoint_path_2 = \"gdrive/My Drive/data/weights_1/arch4rms.ckpt\"\n",
    "# Create checkpoint callback\n",
    "\n",
    "# Create checkpoint callback and store the best weights alone, discard updating the weights if the 'acc' does not improve\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path_2,monitor='acc',\n",
    "                                                 save_weights_only=True, save_best_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 866
    },
    "colab_type": "code",
    "id": "9ME5B7TtGWI8",
    "outputId": "631a115d-8dd4-431f-d408-0c5df4e32e39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-50-9f722f37aa72>:3: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 98323 samples, validate on 10925 samples\n",
      "Epoch 1/15\n",
      "98323/98323 [==============================] - 493s 5ms/step - loss: 0.4375 - acc: 0.8254 - au_roc: 0.6679 - val_loss: 0.4323 - val_acc: 0.8483 - val_au_roc: 0.7245\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.82540, saving model to gdrive/My Drive/data/weights_1/arch4rms.ckpt\n",
      "Epoch 2/15\n",
      "98323/98323 [==============================] - 488s 5ms/step - loss: 0.3696 - acc: 0.8543 - au_roc: 0.7496 - val_loss: 0.3759 - val_acc: 0.8521 - val_au_roc: 0.7517\n",
      "\n",
      "Epoch 00002: acc improved from 0.82540 to 0.85430, saving model to gdrive/My Drive/data/weights_1/arch4rms.ckpt\n",
      "Epoch 3/15\n",
      "98323/98323 [==============================] - 489s 5ms/step - loss: 0.3430 - acc: 0.8653 - au_roc: 0.7947 - val_loss: 0.3761 - val_acc: 0.8514 - val_au_roc: 0.7372\n",
      "\n",
      "Epoch 00003: acc improved from 0.85430 to 0.86534, saving model to gdrive/My Drive/data/weights_1/arch4rms.ckpt\n",
      "Epoch 4/15\n",
      "98323/98323 [==============================] - 485s 5ms/step - loss: 0.2921 - acc: 0.8852 - au_roc: 0.8628 - val_loss: 0.4202 - val_acc: 0.8474 - val_au_roc: 0.7260\n",
      "\n",
      "Epoch 00004: acc improved from 0.86534 to 0.88515, saving model to gdrive/My Drive/data/weights_1/arch4rms.ckpt\n",
      "Epoch 5/15\n",
      "98323/98323 [==============================] - 487s 5ms/step - loss: 0.2101 - acc: 0.9185 - au_roc: 0.9356 - val_loss: 0.4871 - val_acc: 0.8376 - val_au_roc: 0.7000\n",
      "\n",
      "Epoch 00005: acc improved from 0.88515 to 0.91854, saving model to gdrive/My Drive/data/weights_1/arch4rms.ckpt\n",
      "Epoch 6/15\n",
      "98323/98323 [==============================] - 491s 5ms/step - loss: 0.1261 - acc: 0.9532 - au_roc: 0.9788 - val_loss: 0.6692 - val_acc: 0.8329 - val_au_roc: 0.6735\n",
      "\n",
      "Epoch 00006: acc improved from 0.91854 to 0.95321, saving model to gdrive/My Drive/data/weights_1/arch4rms.ckpt\n",
      "Epoch 7/15\n",
      " 7800/98323 [=>............................] - ETA: 7:14 - loss: 0.0542 - acc: 0.9838 - au_roc: 0.9976"
     ]
    }
   ],
   "source": [
    "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
    "# compiling the model\n",
    "model1.compile(optimizer=rms,loss='categorical_crossentropy',metrics=['accuracy',au_roc])\n",
    "model1.fit([train_padded_docs,encoded_train_state_value,encoded_train_grade_value,encoded_train_category_value,encoded_train_subcategory_value,encoded_train_teacher_value,\n",
    "            train_num],y_train_ohe,validation_data=([test_padded_docs,encoded_test_state_value,encoded_test_grade_value,encoded_test_category_value,\n",
    "                                                                    encoded_test_subcategory_value,encoded_test_teacher_value,test_num],y_test_ohe),epochs=15,batch_size=300,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGcLjIXB_blN"
   },
   "source": [
    "# In epoch 2, we get validation auc greater than 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SGVvoSv0ZO_4"
   },
   "source": [
    "# <center> 'Model-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgxVlfNIaiW7"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"<!--?.*?-->\",\"\",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5-x45Aean47"
   },
   "outputs": [],
   "source": [
    "project_data['essay'] = project_data['essay'].apply(lambda x:pre_process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BjhB03kK90Zm"
   },
   "outputs": [],
   "source": [
    "# Train,test split of essays\n",
    "train_essay,test_essay=train_test_split(project_data['essay'],test_size=0.1,random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7YMV6p_ZW0f"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(use_idf =True,min_df=5)\n",
    "# Fitting on train and getting feautres\n",
    "train_tfidf = tfidf.fit_transform(train_essay)\n",
    "test_tfidf=tfidf.transform(test_essay)\n",
    "feature_names = np.array(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "faAn1e42ZmrD",
    "outputId": "ea809adc-715c-4e73-fd19-e0e0a70c5abb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aaa', 'aac', 'aaron', 'ab', 'aba', 'abacus', 'abandon',\n",
       "       'abandoned', 'abandonment'], dtype='<U19')"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "SFR6WCl5aFIC",
    "outputId": "6d111bfa-31f1-4a0a-fa38-738aa49b3485"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20808"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OdJO84AHcPtt"
   },
   "outputs": [],
   "source": [
    "# sorting idf values in ascending order\n",
    "sorted_idf=np.sort(tfidf.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "R3KPBHbKcfy6",
    "outputId": "95088bdc-e889-48c0-a23c-a06b1c1cad21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00760584,  1.044633  ,  1.1609336 , ..., 10.70426396,\n",
       "       10.70426396, 10.70426396])"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "8YtRMUMShugf",
    "outputId": "43a030e4-e448-40f9-861b-89eae71492da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17822, 12080, 16109, ..., 10604, 10473, 20807])"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting original indices after sorting the based on idf scores\n",
    "sorted_indices=np.argsort(tfidf.idf_)\n",
    "sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "Msn141uJckFw",
    "outputId": "bb113797-5efb-464e-8aa7-57ef818b9cd9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4g2iq14AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.boxplot(sorted_idf)\n",
    "plt.title('Box plot of INVERSE DOCUMENT FREQUENCIES(idf)')\n",
    "plt.xlabel('text category')\n",
    "plt.ylabel('IDF values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "rgHX9MsJdefY",
    "outputId": "1651880c-c89c-4c4a-e30e-cce7a7b9a98c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.65974152,  9.16381892, 10.09812815])"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting idf values in the IQR range(25% ,50% and 75%)\n",
    "np.percentile(sorted_idf,[25,50,75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bI3E2Lv-eutJ"
   },
   "outputs": [],
   "source": [
    "# extracting indices less than idf values 2 and greater than 9, to remove words having idf values in the given \n",
    "# range(2 and greater than 9)\n",
    "\n",
    "indices_within_percentile=np.array(np.where(np.logical_or(sorted_idf<=2 , sorted_idf>=9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "-2Qr0xzpLras",
    "outputId": "f9b178a7-9d03-4823-9d2a-fb92db1ffc06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11083, 1)"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_within_percentile=indices_within_percentile.reshape(-1,1)\n",
    "indices_within_percentile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "CHI-pOHij_vd",
    "outputId": "be3ee8b2-a853-4283-97a4-75a184c19cb4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11083/11083 [00:00<00:00, 568025.11it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "words_to_be_removed=[]\n",
    "for i in tqdm(indices_within_percentile):\n",
    "  a=sorted_indices[i]\n",
    "  words_to_be_removed.append(feature_names[a])\n",
    "  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "aHq2j_8fnm0H",
    "outputId": "8f7045c5-e3b5-4190-ecf8-283d97b8e389"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['students'],\n",
       "       ['nannan'],\n",
       "       ['school'],\n",
       "       ...,\n",
       "       ['lent'],\n",
       "       ['laureates'],\n",
       "       ['zuni']], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_be_removed=np.array(words_to_be_removed,dtype=object)\n",
    "words_to_be_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "sBiR6R6HoCvy",
    "outputId": "662be663-6502-4343-dc30-17b9eaf5aca2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11083"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_to_be_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0n1jYumvxJt"
   },
   "outputs": [],
   "source": [
    "# I found that even after removing the rare and common words,  'i', 'a', 'an', repeating in the sentences, So removing them\n",
    "mostly_used=['i','a','an']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BU46VLYYoHx7"
   },
   "outputs": [],
   "source": [
    "train_new_sentences=[]\n",
    "for sen in tqdm(train_essay):\n",
    "  words=[word for word in sen.split(' ') if word not in words_to_be_removed if word not in mostly_used]\n",
    "  joined_sen=' '.join(words)\n",
    "  train_new_sentences.append(joined_sen) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BepZbHOtVX0n"
   },
   "outputs": [],
   "source": [
    "# Storing the processed 'essay' in a csv file\n",
    "dict={'processed_train_essay':train_new_sentences}\n",
    "df=pd.DataFrame(dict)\n",
    "df.to_csv('gdrive/My Drive/data/processed_idf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "89MI-jwmVpi6",
    "outputId": "c2847204-29c7-4502-fd2d-8c7c1e0963f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>processed_train_essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dream big that motto especially first graders ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sharks amazing group kids literally world chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>motivated engaged ready discover world th grad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>enjoy participating group sports physical educ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              processed_train_essay\n",
       "0           0  dream big that motto especially first graders ...\n",
       "1           1  sharks amazing group kids literally world chan...\n",
       "2           2  motivated engaged ready discover world th grad...\n",
       "3           3  enjoy participating group sports physical educ..."
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "idf_df=pd.read_csv('gdrive/My Drive/data/processed_idf.csv')\n",
    "idf_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PKScQGG3DS5K"
   },
   "outputs": [],
   "source": [
    "test_new_sentences=[]\n",
    "for sen in tqdm(test_essay):\n",
    "  words=[word for word in sen.split(' ') if word not in words_to_be_removed if word not in mostly_used]\n",
    "  joined_sen=' '.join(words)\n",
    "  test_new_sentences.append(joined_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XOsrvf-5HArR"
   },
   "outputs": [],
   "source": [
    "# Storing the processed 'essay' in a csv file\n",
    "dict={'processed_test_essay':test_new_sentences}\n",
    "df=pd.DataFrame(dict)\n",
    "df.to_csv('gdrive/My Drive/data/processed_idf_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "woObadfyZOwX",
    "outputId": "34eb7424-6770-4f49-a842-e12d95b03fb5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>processed_test_essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>there genuinely sufficient resources world ens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>can imagine life without lego bricks some firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>as year moves second graders ready take new ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>teach th grade special education low socioecon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                               processed_test_essay\n",
       "0           0  there genuinely sufficient resources world ens...\n",
       "1           1  can imagine life without lego bricks some firs...\n",
       "2           2  as year moves second graders ready take new ex...\n",
       "3           3  teach th grade special education low socioecon..."
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the processed test essay that contain words in the IDR range\n",
    "idf_df_test=pd.read_csv('gdrive/My Drive/data/processed_idf_test.csv')\n",
    "idf_df_test.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vs0X3w8ayHrc"
   },
   "source": [
    "# Comparing new sentences with old ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "wiFmKsRYQ-d4",
    "outputId": "8be80c1d-7d61-4154-f9d6-b0c8fd235161"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dream big that motto school especially first graders strive coming st grade brains ready grow undeniable enthusiasm school they strive everyday best selves and crown heights area title school need resources help now time help achieve goals identify readers i requesting sets leveled books a d benefit library three st grade classrooms by leveled texts classroom library students books choose as shop books access books different genres fit interest by donating project helping generate love reading attaining books go long way ensuring students build maintain important interest i thank advance desire make difference nannan'"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_essay[69364]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "I9gkyrCZs09a",
    "outputId": "b74fbbcd-4fd1-4fcc-e3c9-90d03b30219d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dream big that motto especially first graders strive coming st grade brains ready grow undeniable enthusiasm strive everyday best selves and heights area title resources now time achieve goals identify readers requesting sets leveled books d benefit library three st grade classrooms by leveled texts library books choose as shop books access books different genres fit interest by donating project helping generate reading attaining books go long way ensuring build maintain important interest thank advance desire difference'"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_df['processed_train_essay'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9OrxXL-XqvRA"
   },
   "outputs": [],
   "source": [
    "# TRAIN data\n",
    "# Creating vocab for new sentences(after removal of rare and common words in the sentences)\n",
    "tokenizer.fit_on_texts(idf_df['processed_train_essay'])\n",
    "vocab_size_idf = len(tokenizer.word_index)\n",
    "# Creating numbers for each word in the corpus\n",
    "encoded_docs_idf = tokenizer.texts_to_sequences(idf_df['processed_train_essay'])\n",
    "# Padding with max_length=100\n",
    "max_length = 100\n",
    "padded_docs_idf = pad_sequences(encoded_docs_idf, maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "colab_type": "code",
    "id": "bzbGhvhpaQAk",
    "outputId": "e97cdf8f-1ceb-4d2a-d1cf-df6443051bc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 873,  407,  635, 1824,  393,   59,  119,  353,  358,  443,   19,\n",
       "       1034,  141,  174, 9675,  904,  353,  208,   40, 4115,  789, 2915,\n",
       "        137,  108,   85, 1256,   14,  364,  269, 1407,  183,  347,  765,\n",
       "        984,   10,  913,  249,  167,  461,  443,   19,  360,  177,  984,\n",
       "        590,  167,   10,  288,  101, 2606,   10,   54,   10,   37, 1504,\n",
       "        716,  328,  177,  805,   36,  346, 3410,    3, 6821,   10,  164,\n",
       "        250,   43, 2684,  157, 1057,  129,  328,  385, 1143,  473,  381,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0], dtype=int32)"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs_idf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Ug9r-qblQ1tk",
    "outputId": "25ae32d8-b8da-4908-d92a-a8eeb5346ea5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98323"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_docs_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WeH54g_XKhph"
   },
   "outputs": [],
   "source": [
    "# TEST data\n",
    "# Creating numbers for each word in the corpus\n",
    "encoded_docs_idf_test = tokenizer.texts_to_sequences(idf_df_test['processed_test_essay'])\n",
    "# Padding with max_length=100\n",
    "max_length = 100\n",
    "padded_docs_idf_test = pad_sequences(encoded_docs_idf_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "Ez3VrsI_aurS",
    "outputId": "93de7b44-d6a5-4e68-e7e6-ef2c380a7ae2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  278,  3802,  3084,    85,    31,   472,   168,    17,   168,\n",
       "         168,    14,   164,   871,  2345, 54117,    32,   100,    62,\n",
       "        2284,    59,   119,   988,   182,   384,   108,   975,  1903,\n",
       "         334,   225,  1389,    50,   149,   655,    71,   196,   168,\n",
       "         334,  5246,   473,    68,    65,     8,    27,   287,   614,\n",
       "        1186,    42,   220,  2005,   829,   796,  2480,   163,    15,\n",
       "         871,   490,   256,  1012,  1386,  1192,   256,     5,   230,\n",
       "        1092,   796,   288,   295,   348,  1594,   499,    71,    38,\n",
       "         302,    14,  1150,  2247,  3400,   166,   177,   805,    36,\n",
       "          59,   119,  1272,  6210,  6422, 24023,   610,    23,   117,\n",
       "         129,   526,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0], dtype=int32)"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs_idf_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "_PB9uhKE-FQL",
    "outputId": "ec97a754-a6b0-41d8-a7cd-1069bd67c471"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56176"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7n19RjYB9p0C"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words  in training docs in model 2\n",
    "\n",
    "weight_matrix_2 = np.zeros((vocab_size_idf+1, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "  vector = model.get(word)\n",
    "  if vector is not None:\n",
    "\t\t weight_matrix_2[i] = vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f55DE7CV6p1g"
   },
   "outputs": [],
   "source": [
    "# Define text input model 2\n",
    "text_input_2 = Input(shape=(100,), name='text_input')\n",
    "text_emb_2=(Embedding(input_dim=vocab_size_idf+1,output_dim=300,weights=[weight_matrix_2],input_length=100,trainable=False))(text_input_2)\n",
    "text_lstm_2=(LSTM(100,return_sequences=True))(text_emb_2)\n",
    "text_flatten_2=(Flatten())(text_lstm_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IA7WuOkc6_Ea"
   },
   "outputs": [],
   "source": [
    "combined_2=concatenate([text_flatten_2,school_state_flatten,grade_flatten,category_flatten,subcategory_flatten,teacher_flatten,numerical_input_flatten])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzYKidy966aN"
   },
   "outputs": [],
   "source": [
    "# After combining layers\n",
    "den1=Dense(units=300,activation='relu',kernel_initializer='glorot_uniform')(combined)\n",
    "dropout1=Dropout(0.3)(den1)\n",
    "den2=Dense(units=100,activation='relu',kernel_initializer='glorot_uniform')(dropout1)\n",
    "bn1=BatchNormalization()(den2)\n",
    "softmax_output=Dense(units=2,activation='softmax')(bn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAZIUn1e66ak"
   },
   "outputs": [],
   "source": [
    "model2=Model(inputs=[text_input,school_state_input,grade_input,category_input,subcategory_input,teacher_input,numerical_input],outputs=[softmax_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hTv1tB_66aq"
   },
   "outputs": [],
   "source": [
    "# check point path\n",
    "checkpoint_path_2 = \"gdrive/My Drive/data/weights_2/rms.ckpt\"\n",
    "# Create checkpoint callback\n",
    "\n",
    "# Create checkpoint callback and store the best weights alone, discard updating the weights if the 'acc' does not improve\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path_2,monitor='acc',\n",
    "                                                 save_weights_only=True, save_best_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "colab_type": "code",
    "id": "inBm8cZR66aw",
    "outputId": "7079856c-02c3-4714-c874-bb220689e928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98323 samples, validate on 10925 samples\n",
      "Epoch 1/15\n",
      "98323/98323 [==============================] - 483s 5ms/step - loss: 0.3881 - acc: 0.8379 - au_roc: 0.7704 - val_loss: 0.3852 - val_acc: 0.8416 - val_au_roc: 0.7445\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.83791, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 2/15\n",
      "98323/98323 [==============================] - 481s 5ms/step - loss: 0.2963 - acc: 0.8857 - au_roc: 0.8592 - val_loss: 0.4409 - val_acc: 0.8176 - val_au_roc: 0.7293\n",
      "\n",
      "Epoch 00002: acc improved from 0.83791 to 0.88570, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 3/15\n",
      "98323/98323 [==============================] - 482s 5ms/step - loss: 0.2553 - acc: 0.9037 - au_roc: 0.9014 - val_loss: 0.5079 - val_acc: 0.7972 - val_au_roc: 0.7112\n",
      "\n",
      "Epoch 00003: acc improved from 0.88570 to 0.90371, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 4/15\n",
      "98323/98323 [==============================] - 482s 5ms/step - loss: 0.2077 - acc: 0.9219 - au_roc: 0.9369 - val_loss: 0.5775 - val_acc: 0.7635 - val_au_roc: 0.6847\n",
      "\n",
      "Epoch 00004: acc improved from 0.90371 to 0.92190, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 5/15\n",
      "98323/98323 [==============================] - 482s 5ms/step - loss: 0.1594 - acc: 0.9401 - au_roc: 0.9634 - val_loss: 0.6188 - val_acc: 0.7941 - val_au_roc: 0.6815\n",
      "\n",
      "Epoch 00005: acc improved from 0.92190 to 0.94006, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 6/15\n",
      "98323/98323 [==============================] - 482s 5ms/step - loss: 0.1179 - acc: 0.9571 - au_roc: 0.9808 - val_loss: 0.8691 - val_acc: 0.7912 - val_au_roc: 0.7093\n",
      "\n",
      "Epoch 00006: acc improved from 0.94006 to 0.95712, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 7/15\n",
      "98323/98323 [==============================] - 485s 5ms/step - loss: 0.0854 - acc: 0.9706 - au_roc: 0.9894 - val_loss: 0.6951 - val_acc: 0.8276 - val_au_roc: 0.6920\n",
      "\n",
      "Epoch 00007: acc improved from 0.95712 to 0.97059, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 8/15\n",
      "98323/98323 [==============================] - 484s 5ms/step - loss: 0.0653 - acc: 0.9773 - au_roc: 0.9939 - val_loss: 0.6687 - val_acc: 0.8079 - val_au_roc: 0.6556\n",
      "\n",
      "Epoch 00008: acc improved from 0.97059 to 0.97728, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 9/15\n",
      "98323/98323 [==============================] - 481s 5ms/step - loss: 0.0512 - acc: 0.9822 - au_roc: 0.9961 - val_loss: 0.7852 - val_acc: 0.7906 - val_au_roc: 0.6659\n",
      "\n",
      "Epoch 00009: acc improved from 0.97728 to 0.98224, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 10/15\n",
      "98323/98323 [==============================] - 482s 5ms/step - loss: 0.0445 - acc: 0.9853 - au_roc: 0.9970 - val_loss: 1.0315 - val_acc: 0.8115 - val_au_roc: 0.6907\n",
      "\n",
      "Epoch 00010: acc improved from 0.98224 to 0.98529, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 11/15\n",
      "98323/98323 [==============================] - 482s 5ms/step - loss: 0.0402 - acc: 0.9869 - au_roc: 0.9971 - val_loss: 1.0548 - val_acc: 0.7789 - val_au_roc: 0.6817\n",
      "\n",
      "Epoch 00011: acc improved from 0.98529 to 0.98689, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 12/15\n",
      "98323/98323 [==============================] - 486s 5ms/step - loss: 0.0356 - acc: 0.9884 - au_roc: 0.9978 - val_loss: 1.1287 - val_acc: 0.7519 - val_au_roc: 0.6869\n",
      "\n",
      "Epoch 00012: acc improved from 0.98689 to 0.98845, saving model to gdrive/My Drive/data/weights_1/arch3rms.ckpt\n",
      "Epoch 13/15\n",
      " 7200/98323 [=>............................] - ETA: 7:13 - loss: 0.0225 - acc: 0.9938 - au_roc: 0.9984"
     ]
    }
   ],
   "source": [
    "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
    "# compiling the model\n",
    "model2.compile(optimizer=rms,loss='categorical_crossentropy',metrics=['accuracy',au_roc])\n",
    "model2.fit([train_padded_docs,encoded_train_state_value,encoded_train_grade_value,encoded_train_category_value,encoded_train_subcategory_value,encoded_train_teacher_value,\n",
    "            train_num],y_train_ohe,validation_data=([test_padded_docs,encoded_test_state_value,encoded_test_grade_value,encoded_test_category_value,\n",
    "                                                                    encoded_test_subcategory_value,encoded_test_teacher_value,test_num],y_test_ohe),epochs=15,batch_size=300,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RjSpyuII_0i-"
   },
   "source": [
    "# In many epoch we get validation auc greater than 0.70 for model 2, so stopping the hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RhYQKt84PX0F"
   },
   "source": [
    "# <center> MODEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "id": "hpy39_0pQTfB",
    "outputId": "83e3cd21-7606-44eb-b2f7-8f4cbaf74fc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school_state', 'teacher_prefix', 'project_grade_category',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
       "       'clean_categories', 'clean_subcategories', 'essay', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OtNXT0sPWjp"
   },
   "outputs": [],
   "source": [
    "# Train and test split\n",
    "tr_state,te_state,tr_grade,te_grade,tr_cat,te_cat,tr_subcat,te_subcat,tr_teacher,te_teacher,tr_price,te_price,tr_posted,te_posted= train_test_split(project_data['school_state'].values,project_data['project_grade_category'].values,project_data['clean_categories'].values,\n",
    "                                             project_data['clean_subcategories'].values,project_data['teacher_prefix'].values,project_data['price'].values,\n",
    "                                             project_data['teacher_number_of_previously_posted_projects'].values,test_size=0.1,random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QTr1BzBVcRhz"
   },
   "outputs": [],
   "source": [
    "# One hot encoder\n",
    "one_hot_encoding=OneHotEncoder(handle_unknown='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fFbJ8VkTdQPc"
   },
   "outputs": [],
   "source": [
    "# One Hot Encodong categorical features\n",
    "tr_state_ohe=(one_hot_encoding.fit_transform((tr_state).reshape(-1,1)))\n",
    "te_state_ohe=(one_hot_encoding.transform((te_state).reshape(-1,1)))\n",
    "\n",
    "\n",
    "tr_grade_ohe=(one_hot_encoding.fit_transform(tr_grade.reshape(-1,1)))\n",
    "te_grade_ohe=(one_hot_encoding.transform(te_grade.reshape(-1,1)))\n",
    "\n",
    "tr_cat_ohe=(one_hot_encoding.fit_transform(tr_cat.reshape(-1,1)))\n",
    "te_cat_ohe=(one_hot_encoding.transform(te_cat.reshape(-1,1)))\n",
    "\n",
    "\n",
    "tr_subcat_ohe=(one_hot_encoding.fit_transform(tr_subcat.reshape(-1,1)))\n",
    "\n",
    "te_subcat_ohe=(one_hot_encoding.transform(te_subcat.reshape(-1,1)))\n",
    "\n",
    "tr_teacher_ohe=(one_hot_encoding.fit_transform(tr_teacher.reshape(-1,1)))\n",
    "te_teacher_ohe=(one_hot_encoding.transform(te_teacher.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "JE_auY80db8b",
    "outputId": "7c5452d8-3726-4750-f48d-65beb2487e0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98323, 51)"
      ]
     },
     "execution_count": 122,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_cat_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "bloLfvIMQ-lQ",
    "outputId": "410ff81f-cf02-4ca4-abad-eae6f8093ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98323, 51)\n",
      "(98323, 4)\n",
      "(98323, 51)\n",
      "(98323, 397)\n",
      "(98323, 5)\n"
     ]
    }
   ],
   "source": [
    "print(tr_state_ohe.shape)\n",
    "print(tr_grade_ohe.shape)\n",
    "print(tr_cat_ohe.shape)\n",
    "print(tr_subcat_ohe.shape)\n",
    "print(tr_teacher_ohe.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "6vn1sArLDncE",
    "outputId": "b495a39a-9ac7-4395-fe85-c0e7e4c1c664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10925, 51)\n",
      "(10925, 4)\n",
      "(10925, 51)\n",
      "(10925, 397)\n",
      "(10925, 5)\n"
     ]
    }
   ],
   "source": [
    "print(te_state_ohe.shape)\n",
    "print(te_grade_ohe.shape)\n",
    "print(te_cat_ohe.shape)\n",
    "print(te_subcat_ohe.shape)\n",
    "print(te_teacher_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0phNw5Lfdyy"
   },
   "outputs": [],
   "source": [
    "tr_price=tr_price.reshape(-1,1)\n",
    "tr_posted=tr_posted.reshape(-1,1)\n",
    "te_price=te_price.reshape(-1,1)\n",
    "te_posted=te_posted.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "RxYlVB_dfxeS",
    "outputId": "fc230ae6-5644-4eed-f417-93ba55aecb40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98323, 1)"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TxN9B8jpETDQ"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "X_train=hstack((tr_state_ohe,tr_grade_ohe,tr_cat_ohe,tr_subcat_ohe,tr_teacher_ohe,tr_price,tr_posted))\n",
    "\n",
    "X_test=hstack((te_state_ohe,te_grade_ohe,te_cat_ohe,te_subcat_ohe,te_teacher_ohe,te_price,te_posted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "5G5H9GdnKoEi",
    "outputId": "de5b1f23-54f6-4421-c611-e0376520c2b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98323, 510)\n",
      "(10925, 510)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.toarray()\n",
    "X_test=X_test.toarray()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "XXY9_YtHDEk3",
    "outputId": "45db41f6-bcdb-425d-e7e8-7bfa5766fa98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98323, 510, 1)\n",
      "(10925, 510, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train=np.reshape(X_train,(98323,510,-1))\n",
    "X_test=np.reshape(X_test,(10925,510,-1))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VCtBqZ4cDEcq"
   },
   "outputs": [],
   "source": [
    "#defining the model\n",
    "batch_size=300\n",
    "numerical_input=Input(shape=(510,1))\n",
    "conv1=Conv1D(filters=200, kernel_size=50, activation='relu', input_shape=(510,1))(numerical_input)\n",
    "conv2=Conv1D(100, 50, activation='relu')(conv1)\n",
    "\n",
    "conv3=Conv1D(100, 50, activation='relu')(conv2)\n",
    "max_pool1=MaxPooling1D(5)(conv3)# output shape is  [30,100] \n",
    "conv4=Conv1D(100, 50, activation='relu')(max_pool1)\n",
    "flatten3=Flatten()(conv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlXe1mXFf4IP"
   },
   "outputs": [],
   "source": [
    "combined_3=concatenate([text_flatten,flatten3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "wrXgf34ykZpb",
    "outputId": "c2d57115-9c06-4115-a27f-2b7913021fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After combining layers\n",
    "den1=Dense(units=100,activation='relu',kernel_initializer='he_normal')(combined_3)\n",
    "dropout1=Dropout(0.4)(den1)\n",
    "den2=Dense(units=50,activation='relu',kernel_initializer='he_normal')(dropout1)\n",
    "bn1=BatchNormalization()(den2)\n",
    "dropout2=Dropout(0.3)(bn1)\n",
    "den3=Dense(units=25,activation='relu',kernel_initializer='he_normal')(dropout2)\n",
    "bn2=BatchNormalization()(den3)\n",
    "den4=Dense(units=10,activation='relu',kernel_initializer='he_normal')(bn2)\n",
    "bn3=BatchNormalization()(den4)\n",
    "dropout3=Dropout(0.3)(bn3)\n",
    "softmax_output=Dense(units=2,activation='softmax')(dropout3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngZtkayqEyog"
   },
   "outputs": [],
   "source": [
    "model3=Model(inputs=[text_input,numerical_input],outputs=[softmax_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5SG2XywE25O"
   },
   "outputs": [],
   "source": [
    "adagrad=keras.optimizers.Adagrad(lr=0.01)\n",
    "model3.compile(optimizer=adagrad,loss='categorical_crossentropy',metrics=['accuracy',au_roc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 911
    },
    "colab_type": "code",
    "id": "6VJm-Fs1E5te",
    "outputId": "c57a84fc-63b9-4802-c7c5-4c246ffc9922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 510, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 461, 200)     10200       input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 412, 100)     1000100     conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "text_input (InputLayer)         (None, 600)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 363, 100)     500100      conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 600, 300)     20387700    text_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 72, 100)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 600, 250)     551000      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 23, 100)      500100      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 150000)       0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 2300)         0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 152300)       0           flatten_1[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 100)          15230100    concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 100)          0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 50)           5050        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 50)           200         dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 50)           0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 25)           1275        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25)           100         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 10)           260         batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 10)           40          dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 10)           0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 2)            22          dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 38,186,247\n",
      "Trainable params: 17,798,377\n",
      "Non-trainable params: 20,387,870\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "id": "oSWAsRrSFMSy",
    "outputId": "276b7bd4-711b-4ddb-e5b3-061406985171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98323 samples, validate on 10925 samples\n",
      "Epoch 1/1\n",
      "98323/98323 [==============================] - 524s 5ms/step - loss: 0.3253 - acc: 0.8831 - au_roc: 0.8220 - val_loss: 0.4459 - val_acc: 0.8486 - val_au_roc: 0.7231\n",
      "\n",
      "Epoch 00001: saving model to gdrive/My Drive/data/weights_3/cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0dbdbe3080>"
      ]
     },
     "execution_count": 141,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the latest weights)\n",
    "model3.load_weights(\"gdrive/My Drive/data/weights_3/cp.ckpt\")\n",
    "model3.fit([train_padded_docs,X_train],y_train_ohe,validation_data=([test_padded_docs,X_test],y_test_ohe),epochs=1,batch_size=500,callbacks = [cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4rQt6RnGBVN"
   },
   "source": [
    "# Validation auc is greater than 0.70, So stopping hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM practice.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
